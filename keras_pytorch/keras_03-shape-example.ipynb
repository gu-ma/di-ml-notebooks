{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "To run this code you will need to install [Matplotlib](https://matplotlib.org/users/installing.html) and [Numpy](https://www.scipy.org/install.html)\n",
    "\n",
    "If you like to run the example locally follow the instructions provided on [Keras website](https://keras.io/#installation)\n",
    "\n",
    "It's __strongly__ suggested to use a Python environments manager such as [Conda](https://conda.io/docs/) or some kind of [VirutalEnv](#)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/digitalideation/digcre_h2301/blob/master/samples/week02/03-shape-example.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downgrade Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib==3.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A second look at a neural network\n",
    "\n",
    "Let's try to adapt the shape classification model built with the `toyNN` in js before.\n",
    "\n",
    "We first need to create a dataset _manually_ to do we will define a `draw_shape` function that will help generating some random shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 0 = rectangle, 1 = triangle, 2 = ellipse\n",
    "# return shape\n",
    "def draw_shape(max_size, type):\n",
    "\n",
    "    # Not so random size and random coordinate\n",
    "    s = int(max_size/2 + random.random() * max_size/2)\n",
    "    x = int(s/2) + random.random() * (max_size-s)\n",
    "    y = int(s/2) + random.random() * (max_size-s)\n",
    "\n",
    "    type = type%3\n",
    "    \n",
    "    if type == 0:\n",
    "        art = plt.Rectangle((x-s/2, y-s/2), s, s, color='r')\n",
    "\n",
    "    if type == 1:\n",
    "        verts = [\n",
    "            (x-s/2, y-s/2),\n",
    "            (x, y+s/2),\n",
    "            (x+s/2, y-s/2)\n",
    "        ]\n",
    "        art = plt.Polygon(verts, color='r')\n",
    "\n",
    "    if type == 2:\n",
    "        art = plt.Circle((x, y), s/2, color='r')\n",
    "    \n",
    "    return art"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a helper function that convert a matplotlib figure to a np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/a/7821917\n",
    "def fig2rgb_array(fig):\n",
    "    fig.canvas.draw()\n",
    "    buf = fig.canvas.tostring_rgb()\n",
    "    ncols, nrows = fig.canvas.get_width_height()\n",
    "    return np.frombuffer(buf, dtype=np.uint8).reshape(nrows, ncols, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the function see if it works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image and dataset size we are going to use\n",
    "image_size = 48.0\n",
    "dataset_size = 500\n",
    "\n",
    "# Create plot's figure and axes\n",
    "# https://stackoverflow.com/a/638443\n",
    "fig = plt.figure(figsize=(1,1), dpi=image_size)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Setting for the axes\n",
    "ax.set_xlim(0,image_size)\n",
    "ax.set_ylim(0,image_size)\n",
    "# ax.axis('off')\n",
    "\n",
    "# Draw a random shape\n",
    "art = draw_shape(image_size,random.randint(0,2))\n",
    "# Add the shape to the plot\n",
    "# https://stackoverflow.com/a/29184075\n",
    "plt.gcf().gca().add_artist(art)\n",
    "# gcf() means Get Current Figure\n",
    "# gca() means Get Current Axis\n",
    "\n",
    "# convert the figure to an array\n",
    "data = fig2rgb_array(fig)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a loop that will generate a small dataset for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(image_size, dataset_size):\n",
    "\n",
    "    # Those variable will contain the images and associated labels\n",
    "    images = np.zeros((dataset_size, image_size, image_size, 3))\n",
    "    labels = np.zeros((dataset_size))\n",
    "    \n",
    "    # The plot figure we will use to generate the shapes\n",
    "    fig = plt.figure(figsize=(1,1), dpi=image_size)\n",
    "\n",
    "    for i in range(dataset_size):\n",
    "        \n",
    "        # Clear the figure\n",
    "        fig.clf()\n",
    "        \n",
    "        # Recreate the axes\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.set_xlim(0, image_size)\n",
    "        ax.set_ylim(0, image_size)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Define label\n",
    "        label = i%3\n",
    "        art = draw_shape(image_size, label)\n",
    "        plt.gcf().gca().add_artist(art)\n",
    "        \n",
    "        # Add values to the arrays\n",
    "        images[i] = fig2rgb_array(fig)\n",
    "        labels[i] = label\n",
    "        \n",
    "    return images, labels\n",
    "\n",
    "# Generate our dataset\n",
    "images, labels = generate_dataset(int(image_size), dataset_size)\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually we can save our dataset for later, since it takes quite some time to generate it ðŸ˜‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('datasets/shape-example-shapes1.npy', images)\n",
    "np.save('datasets/shape-example-labels1.npy', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we need to load it we can then use the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load('datasets/shape-example-shapes1.npy')\n",
    "labels = np.load('datasets/shape-example-labels1.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split our dataset manually in training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of the training set, here we use 80% of the total samples for training\n",
    "train_size = int(dataset_size*.8)\n",
    "\n",
    "# TODO: We should shuffle the dataset\n",
    "\n",
    "# Split the dataset into train and test dataset\n",
    "train_images, test_images = images[:train_size], images[train_size:]\n",
    "train_labels, test_labels = labels[:train_size], labels[train_size:]\n",
    "\n",
    "# Verify the data\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "# sample_images = []\n",
    "# for label, image in list(zip(train_labels, train_images))[:10]:\n",
    "#     fig1, ax1 = plt.subplots()\n",
    "#     ax1.axis('off')\n",
    "#     plt.title(label)\n",
    "#     fig1.add_subplot(111).imshow(image/255)\n",
    "\n",
    "full_image = np.concatenate(train_images[:12]/255, axis=1)\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.imshow(full_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"sigmoid\"),\n",
    "    layers.Dense(3, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, we will preprocess our data by reshaping it into the shape that the network expects, and scaling it so that all values are in the `[0, 1]` interval. Then we also need to categorically encode the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data\n",
    "image_size = int(image_size)\n",
    "train_images = train_images.reshape((len(train_images), 3 * image_size * image_size))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((len(test_images), 3 * image_size * image_size))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# Encode to categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_images, train_labels, epochs=100, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show images which were wrongly predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for label, image in list(zip(test_labels, test_images)):\n",
    "    prediction = model.predict(np.array([image,]))\n",
    "    if not prediction.argmax() == label.argmax():\n",
    "        image = image.reshape(48, 48, 3)\n",
    "        fig1, ax1 = plt.subplots()\n",
    "        ax1.axis('off')\n",
    "        plt.title('predicted:' + str(prediction.argmax()))\n",
    "        fig1.add_subplot(111).imshow(image)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
